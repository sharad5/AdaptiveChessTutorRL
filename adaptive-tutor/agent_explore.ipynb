{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import adaptive_tutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "action_space = np.load('adaptive_tutor/action_space.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TutorStatefulAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float,\n",
    "        initial_epsilon: float,\n",
    "        epsilon_decay: float,\n",
    "        final_epsilon: float,\n",
    "        discount_factor: float = 0.95,\n",
    "    ):\n",
    "        \"\"\"Initialize a Reinforcement Learning agent with an empty dictionary\n",
    "        of state-action values (q_values), a learning rate and an epsilon.\n",
    "\n",
    "        Args:\n",
    "            learning_rate: The learning rate\n",
    "            initial_epsilon: The initial epsilon value\n",
    "            epsilon_decay: The decay for epsilon\n",
    "            final_epsilon: The final epsilon value\n",
    "            discount_factor: The discount factor for computing the Q-value\n",
    "        \"\"\"\n",
    "\n",
    "        self.action_space = list(np.load('adaptive_tutor/action_space.npy', allow_pickle=True))\n",
    "        self.q_values = defaultdict(lambda: np.zeros(len(self.action_space)))\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "\n",
    "        self.epsilon = initial_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.final_epsilon = final_epsilon\n",
    "\n",
    "        self.training_error = []\n",
    "\n",
    "    def _create_rating_bracket(self, row):\n",
    "        if row<1300:\n",
    "            return 'lt_1300'\n",
    "        elif 1300<=row<1700:\n",
    "            return '1300-1800'\n",
    "        else:\n",
    "            return 'gt_1700'\n",
    "    \n",
    "    def _get_agent_state(self, obs):\n",
    "        return tuple([self._create_rating_bracket(val) for val in obs['themes_covered']])\n",
    "\n",
    "    def get_action(self, obs: tuple[int, int, bool]) -> int:\n",
    "        \"\"\"\n",
    "        Returns the best action with probability (1 - epsilon)\n",
    "        otherwise a random action with probability epsilon to ensure exploration.\n",
    "        \"\"\"\n",
    "        # with probability epsilon return a random action to explore the environment\n",
    "        obs = self._get_agent_state(obs)\n",
    "        if np.random.random() < self.epsilon:\n",
    "            print(\"Exploring\")\n",
    "            return random.choice(range(len(self.action_space)))\n",
    "\n",
    "        # with probability (1 - epsilon) act greedily (exploit)\n",
    "        else:\n",
    "            return (np.argmax(self.q_values[obs]))\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        obs: tuple[int, int, bool],\n",
    "        action: int,\n",
    "        reward: float,\n",
    "        terminated: bool,\n",
    "        next_obs: tuple[int, int, bool],\n",
    "    ):\n",
    "        \"\"\"Updates the Q-value of an action.\"\"\"\n",
    "        obs = self._get_agent_state(obs)\n",
    "        next_obs = self._get_agent_state(next_obs)\n",
    "        future_q_value = (not terminated) * np.max(self.q_values[next_obs])\n",
    "        temporal_difference = (\n",
    "            reward + self.discount_factor * future_q_value - self.q_values[obs][action]\n",
    "        )\n",
    "\n",
    "        self.q_values[obs][action] = (\n",
    "            self.q_values[obs][action] + self.lr * temporal_difference\n",
    "        )\n",
    "        self.training_error.append(temporal_difference)\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.final_epsilon, self.epsilon - self.epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "n_episodes = 100\n",
    "start_epsilon = 0.5\n",
    "epsilon_decay = start_epsilon / (n_episodes / 2) # Reduce the exploration over time\n",
    "final_epsilon = 0.1\n",
    "\n",
    "agent = TutorStatefulAgent(\n",
    "    learning_rate=learning_rate,\n",
    "    initial_epsilon=start_epsilon,\n",
    "    epsilon_decay=epsilon_decay,\n",
    "    final_epsilon=final_epsilon,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../maia_weights/maia_1100.pb\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]<UciProtocol (pid=56771)>: stderr >> \u001b[1m\u001b[31m       _\n",
      "<UciProtocol (pid=56771)>: stderr >> |   _ | |\n",
      "<UciProtocol (pid=56771)>: stderr >> |_ |_ |_|\u001b[0m v0.30.0+git.dirty built Jul 22 2023\n",
      "<UciProtocol (pid=56771)>: stderr >> Loading weights file from: ../maia_weights/maia_1100.pb\n",
      "<UciProtocol (pid=56771)>: stderr >> Creating backend [metal]...\n",
      "<UciProtocol (pid=56771)>: stderr >> Initialized metal backend on device Apple M2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['checkmating_tactics' '1' 'gt_1900']]\n",
      "[['advanced_tactical_themes' '1' '1000-1100']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chitvangoyal/anaconda3/envs/rl_chess/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/Users/chitvangoyal/anaconda3/envs/rl_chess/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['checkmate_patterns' '1' '1000-1100']]\n",
      "[['checkmating_tactics' '1' '1000-1100']]\n",
      "[['defensive_tactics' '1' '1400-1500']]\n",
      "[['advanced_tactical_themes' '1' '1000-1100']]\n",
      "[['checkmate_patterns' '1' '1300-1400']]\n",
      "[['special_moves' '0' 'gt_1900']]\n",
      "[['defensive_tactics' '1' '1400-1500']]\n",
      "[['checkmate_patterns' '1' '1000-1100']]\n",
      "[['tactical_themes' '0' '1400-1500']]\n",
      "[['tactical_themes' '0' '1300-1400']]\n",
      "[['checkmating_tactics' '1' '1000-1100']]\n",
      "[['piece_specific_endgames' '1' '1500-1600']]\n",
      "[['tactical_themes' '1' '1800-1900']]\n",
      "../maia_Weights/maia_1300.pb\n",
      "2\n",
      "Bot_Upgraded\n",
      "[['advanced_tactical_themes' '1' '1000-1100']]\n",
      "../maia_Weights/maia_1500.pb\n",
      "3\n",
      "Bot_Upgraded\n",
      "[['defensive_tactics' '1' '1400-1500']]\n",
      "[['king_safety_and_attack' '1' '1000-1100']]\n",
      "[['checkmate_patterns' '1' '1000-1100']]\n",
      "[['checkmating_tactics' '1' '1000-1100']]\n",
      "[['advanced_tactical_themes' '0' '1000-1100']]\n",
      "[['checkmate_patterns' '1' '1000-1100']]\n",
      "[['special_moves' '1' '1100-1200']]\n",
      "[['checkmating_tactics' '1' '1700-1800']]\n",
      "[['checkmating_tactics' '1' '1000-1100']]\n",
      "[['defensive_tactics' '1' '1000-1100']]\n",
      "[['pawn_related_themes' '1' '1000-1100']]\n",
      "[['piece_specific_endgames' '1' '1000-1100']]\n",
      "[['advanced_tactical_themes' '0' '1000-1100']]\n",
      "[['special_moves' '1' '1700-1800']]\n",
      "[['strategic_concepts' '1' '1400-1500']]\n",
      "[['advanced_tactical_themes' '1' '1000-1100']]\n",
      "[['defensive_tactics' '1' '1700-1800']]\n",
      "[['checkmate_patterns' '1' '1000-1100']]\n",
      "[['tactical_themes' '0' '1500-1600']]\n",
      "[['advanced_tactical_themes' '1' '900-1000']]\n",
      "[['special_moves' '1' '1800-1900']]\n",
      "[['defensive_tactics' '1' '1200-1300']]\n",
      "[['king_safety_and_attack' '1' '1100-1200']]\n",
      "[['checkmating_tactics' '1' '1000-1100']]\n",
      "[['advanced_tactical_themes' '0' '1000-1100']]\n",
      "[['checkmate_patterns' '1' '1000-1100']]\n",
      "[['defensive_tactics' '1' '1000-1100']]\n",
      "[['defensive_tactics' '0' 'gt_1900']]\n",
      "[['advanced_tactical_themes' '0' 'lt_900']]\n",
      "[['king_safety_and_attack' '0' '1000-1100']]\n",
      "[['pawn_related_themes' '0' '1000-1100']]\n",
      "[['special_moves' '1' '1800-1900']]\n",
      "[['special_moves' '1' '1500-1600']]\n",
      "[['piece_specific_endgames' '1' '1000-1100']]\n",
      "[['special_moves' '1' '1000-1100']]\n",
      "[['pawn_related_themes' '1' '1000-1100']]\n",
      "[['strategic_concepts' '1' '1000-1100']]\n",
      "[['pawn_related_themes' '1' '1500-1600']]\n",
      "[['advanced_tactical_themes' '1' '1000-1100']]\n",
      "[['advanced_tactical_themes' '1' '1800-1900']]\n",
      "[['checkmate_patterns' '1' '1000-1100']]\n",
      "[['checkmating_tactics' '1' '1000-1100']]\n",
      "[['checkmating_tactics' '0' '1000-1100']]\n",
      "[['defensive_tactics' '1' '1300-1400']]\n",
      "[['defensive_tactics' '1' '1000-1100']]\n",
      "[['king_safety_and_attack' '1' '1000-1100']]\n",
      "[['pawn_related_themes' '1' '1000-1100']]\n",
      "[['piece_specific_endgames' '1' '1000-1100']]\n",
      "[['pawn_related_themes' '1' 'lt_900']]\n",
      "[['special_moves' '1' '1000-1100']]\n",
      "[['advanced_tactical_themes' '0' '1400-1500']]\n",
      "[['tactical_themes' '0' '1000-1100']]\n",
      "[['advanced_tactical_themes' '0' '1100-1200']]\n",
      "[['checkmate_patterns' '1' '1100-1200']]\n",
      "[['checkmating_tactics' '1' '1100-1200']]\n",
      "[['defensive_tactics' '1' '1100-1200']]\n",
      "[['pawn_related_themes' '0' '1600-1700']]\n",
      "[['king_safety_and_attack' '1' '1100-1200']]\n",
      "[['defensive_tactics' '1' '1200-1300']]\n",
      "[['advanced_tactical_themes' '1' '1000-1100']]\n",
      "[['defensive_tactics' '1' 'gt_1900']]\n",
      "[['pawn_related_themes' '1' '1100-1200']]\n",
      "[['strategic_concepts' '1' '1600-1700']]\n",
      "[['strategic_concepts' '1' '1000-1100']]\n",
      "[['piece_specific_endgames' '1' '1100-1200']]\n",
      "[['checkmate_patterns' '0' '1600-1700']]\n",
      "[['strategic_concepts' '1' '1400-1500']]\n",
      "[['strategic_concepts' '0' '1000-1100']]\n",
      "[['tactical_themes' '1' '1000-1100']]\n",
      "[['checkmating_tactics' '1' '1500-1600']]\n",
      "[['checkmating_tactics' '1' '1400-1500']]\n",
      "[['king_safety_and_attack' '0' '1700-1800']]\n",
      "[['advanced_tactical_themes' '1' '1000-1100']]\n",
      "[['advanced_tactical_themes' '1' '1100-1200']]\n",
      "[['advanced_tactical_themes' '1' 'gt_1900']]\n",
      "[['checkmate_patterns' '1' '1000-1100']]\n",
      "[['special_moves' '0' '1600-1700']]\n",
      "[['defensive_tactics' '1' '1300-1400']]\n",
      "[['defensive_tactics' '1' 'lt_900']]\n",
      "[['checkmating_tactics' '1' '1000-1100']]\n",
      "[['special_moves' '1' '1800-1900']]\n",
      "[['defensive_tactics' '1' '1000-1100']]\n",
      "[['king_safety_and_attack' '1' '1000-1100']]\n",
      "[['pawn_related_themes' '1' '1000-1100']]\n",
      "[['pawn_related_themes' '1' '1000-1100']]\n",
      "[['defensive_tactics' '1' 'lt_900']]\n",
      "[['advanced_tactical_themes' '1' '1000-1100']]\n",
      "[['checkmate_patterns' '1' '1000-1100']]\n",
      "[['checkmating_tactics' '1' '1800-1900']]\n",
      "[['advanced_tactical_themes' '1' '1000-1100']]\n",
      "[['piece_specific_endgames' '1' '1300-1400']]\n",
      "[['defensive_tactics' '1' '1200-1300']]\n",
      "[['checkmate_patterns' '1' '1000-1100']]\n",
      "[['piece_specific_endgames' '1' '1000-1100']]\n",
      "[['checkmating_tactics' '0' '1000-1100']]\n",
      "[['defensive_tactics' '1' '1000-1100']]\n",
      "[['defensive_tactics' '1' '1600-1700']]\n",
      "[['king_safety_and_attack' '1' '1000-1100']]\n",
      "[['pawn_related_themes' '1' '1000-1100']]\n",
      "[['special_moves' '1' '1000-1100']]\n",
      "[['piece_specific_endgames' '1' 'lt_900']]\n",
      "[['piece_specific_endgames' '1' '1100-1200']]\n",
      "[['pawn_related_themes' '1' '1600-1700']]\n",
      "[['checkmate_patterns' '0' 'gt_1900']]\n",
      "[['strategic_concepts' '1' '1000-1100']]\n",
      "[['advanced_tactical_themes' '1' '1000-1100']]\n",
      "[['tactical_themes' '1' '1800-1900']]\n",
      "[['checkmating_tactics' '1' '1600-1700']]\n",
      "[['checkmate_patterns' '1' '1000-1100']]\n",
      "[['checkmating_tactics' '1' '1000-1100']]\n",
      "[['advanced_tactical_themes' '0' '1800-1900']]\n",
      "[['defensive_tactics' '1' '1000-1100']]\n",
      "[['king_safety_and_attack' '0' '1200-1300']]\n",
      "[['pawn_related_themes' '1' '900-1000']]\n",
      "[['strategic_concepts' '1' '1600-1700']]\n",
      "[['strategic_concepts' '1' '1000-1100']]\n",
      "[['checkmating_tactics' '1' '1700-1800']]\n",
      "[['king_safety_and_attack' '1' '1000-1100']]\n",
      "[['pawn_related_themes' '1' '1000-1100']]\n",
      "[['checkmate_patterns' '0' '1800-1900']]\n",
      "[['special_moves' '1' '1000-1100']]\n",
      "[['piece_specific_endgames' '1' '1000-1100']]\n",
      "[['tactical_themes' '1' '1000-1100']]\n",
      "[['advanced_tactical_themes' '1' '1100-1200']]\n",
      "[['pawn_related_themes' '1' '1800-1900']]\n",
      "[['king_safety_and_attack' '0' '1600-1700']]\n",
      "[['piece_specific_endgames' '0' '1800-1900']]\n",
      "[['advanced_tactical_themes' '0' '1600-1700']]\n",
      "[['checkmate_patterns' '1' '1100-1200']]\n",
      "[['pawn_related_themes' '1' '1100-1200']]\n",
      "[['checkmating_tactics' '1' '1100-1200']]\n",
      "[['tactical_themes' '1' 'gt_1900']]\n",
      "[['defensive_tactics' '1' '1100-1200']]\n",
      "[['pawn_related_themes' '0' '1800-1900']]\n",
      "[['checkmating_tactics' '1' '1000-1100']]\n",
      "[['king_safety_and_attack' '1' '1100-1200']]\n",
      "[['checkmate_patterns' '1' '1500-1600']]\n",
      "[['defensive_tactics' '1' '1800-1900']]\n",
      "[['special_moves' '1' '1200-1300']]\n",
      "[['king_safety_and_attack' '0' '1200-1300']]\n",
      "[['piece_specific_endgames' '1' '1100-1200']]\n",
      "[['special_moves' '1' '1100-1200']]\n",
      "[['pawn_related_themes' '1' '1300-1400']]\n",
      "[['king_safety_and_attack' '0' '1200-1300']]\n",
      "[['tactical_themes' '0' '1800-1900']]\n",
      "[['strategic_concepts' '1' '1100-1200']]\n",
      "[['checkmating_tactics' '0' '900-1000']]\n",
      "[['tactical_themes' '1' '1100-1200']]\n",
      "[['pawn_related_themes' '1' '1000-1100']]\n",
      "[['advanced_tactical_themes' '0' '1200-1300']]\n",
      "[['checkmate_patterns' '0' '1200-1300']]\n",
      "[['defensive_tactics' '1' '1300-1400']]\n",
      "[['checkmating_tactics' '1' '1200-1300']]\n",
      "[['king_safety_and_attack' '1' '900-1000']]\n",
      "[['defensive_tactics' '1' '1200-1300']]\n",
      "[['pawn_related_themes' '0' '1200-1300']]\n",
      "[['tactical_themes' '1' '900-1000']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:24<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pawn_related_themes' '0' '1800-1900']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/chitvangoyal/Desktop/RL_Project/RL/AdaptiveChessTutorRL/adaptive-tutor/agent_explore.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chitvangoyal/Desktop/RL_Project/RL/AdaptiveChessTutorRL/adaptive-tutor/agent_explore.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m step_counter\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chitvangoyal/Desktop/RL_Project/RL/AdaptiveChessTutorRL/adaptive-tutor/agent_explore.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mget_action(obs)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chitvangoyal/Desktop/RL_Project/RL/AdaptiveChessTutorRL/adaptive-tutor/agent_explore.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m next_obs, reward, terminated, truncated, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chitvangoyal/Desktop/RL_Project/RL/AdaptiveChessTutorRL/adaptive-tutor/agent_explore.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#print(action_space[action], reward)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chitvangoyal/Desktop/RL_Project/RL/AdaptiveChessTutorRL/adaptive-tutor/agent_explore.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Update the agent\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chitvangoyal/Desktop/RL_Project/RL/AdaptiveChessTutorRL/adaptive-tutor/agent_explore.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m agent\u001b[39m.\u001b[39mupdate(obs, action, reward, terminated, next_obs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rl_chess/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/anaconda3/envs/rl_chess/lib/python3.9/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/Desktop/RL_Project/RL/AdaptiveChessTutorRL/adaptive-tutor/adaptive_tutor/envs/puzzle_tutor_env.py:174\u001b[0m, in \u001b[0;36mPuzzleTutorEnv.step\u001b[0;34m(self, action_idx)\u001b[0m\n\u001b[1;32m    171\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space_lst[action_idx]\n\u001b[1;32m    173\u001b[0m rating_bracket, theme \u001b[39m=\u001b[39m action\n\u001b[0;32m--> 174\u001b[0m sampled_puzzle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_puzzle(action)\n\u001b[1;32m    175\u001b[0m \u001b[39m# print(sampled_puzzle)\u001b[39;00m\n\u001b[1;32m    176\u001b[0m puzzle_success \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_student_attempt_puzzle(sampled_puzzle)\n",
      "File \u001b[0;32m~/Desktop/RL_Project/RL/AdaptiveChessTutorRL/adaptive-tutor/adaptive_tutor/envs/puzzle_tutor_env.py:78\u001b[0m, in \u001b[0;36mPuzzleTutorEnv._set_puzzle\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_puzzle\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpuzzle_bank\u001b[39m.\u001b[39;49msample_puzzle(action)\n",
      "File \u001b[0;32m~/Desktop/RL_Project/RL/AdaptiveChessTutorRL/adaptive-tutor/adaptive_tutor/envs/components/puzzle_bank.py:19\u001b[0m, in \u001b[0;36mPuzzleBank.sample_puzzle\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39maction: (rating_bracket, theme) tuple\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     18\u001b[0m puzzleId \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbank\u001b[39m.\u001b[39mloc[action]\u001b[39m.\u001b[39mPuzzleId)\n\u001b[0;32m---> 19\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_puzzle(puzzleId)\n",
      "File \u001b[0;32m~/Desktop/RL_Project/RL/AdaptiveChessTutorRL/adaptive-tutor/adaptive_tutor/envs/components/puzzle_bank.py:11\u001b[0m, in \u001b[0;36mPuzzleBank._get_puzzle\u001b[0;34m(self, puzzleId)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_puzzle\u001b[39m(\u001b[39mself\u001b[39m, puzzleId):\n\u001b[0;32m---> 11\u001b[0m     puzzle_row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlichess_data\u001b[39m.\u001b[39mloc[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlichess_data\u001b[39m.\u001b[39;49mPuzzleId\u001b[39m==\u001b[39;49mpuzzleId]\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m puzzle_row\n",
      "File \u001b[0;32m~/anaconda3/envs/rl_chess/lib/python3.9/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/anaconda3/envs/rl_chess/lib/python3.9/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[0;32m~/anaconda3/envs/rl_chess/lib/python3.9/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   6121\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/rl_chess/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[39melif\u001b[39;00m lvalues\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    346\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/rl_chess/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mvec_compare(x\u001b[39m.\u001b[39mravel(), y\u001b[39m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39;49mscalar_compare(x\u001b[39m.\u001b[39;49mravel(), y, op)\n\u001b[1;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load custom environment we created \n",
    "env = gym.make('adaptive_tutor/PuzzleTutorEnv-v0', render_mode=None) \n",
    "\n",
    "# Set to initial state\n",
    "env.reset()\n",
    "\n",
    "episode_rewards = []\n",
    "episode_lengths = []\n",
    "action_rewards = {action: 0 for action in action_space}\n",
    "\n",
    "for episode in tqdm(range(n_episodes)):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    terminated = False\n",
    "    episode_reward = 0\n",
    "    \n",
    "    # Play one episode\n",
    "    step_counter = 0\n",
    "    while not terminated:\n",
    "        step_counter+=1\n",
    "        action = agent.get_action(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        #print(action_space[action], reward)\n",
    "        # Update the agent\n",
    "        agent.update(obs, action, reward, terminated, next_obs)\n",
    "        episode_reward += reward\n",
    "        #print(action_space[action])\n",
    "        # Update the current observation, and whether the environment is done\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "        action_rewards[action_space[action]] += reward\n",
    "    \n",
    "    print(\"Number of steps: \", step_counter)\n",
    "\n",
    "    episode_rewards.append(episode_reward)\n",
    "    episode_lengths.append(step_counter)\n",
    "    print(f\"Episode {episode + 1}: Reward = {episode_reward}, Length = {step_counter}\")\n",
    "\n",
    "\n",
    "    agent.decay_epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.load('adaptive_tutor/action_space.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('1000-1100', 'advanced_tactical_themes'): -75.26578947368421,\n",
       " ('1000-1100', 'checkmate_patterns'): -70.3736842105263,\n",
       " ('1000-1100', 'checkmating_tactics'): -58.37368421052631,\n",
       " ('1000-1100', 'defensive_tactics'): -56.77421052631578,\n",
       " ('1000-1100', 'king_safety_and_attack'): -52.38421052631578,\n",
       " ('1000-1100', 'pawn_related_themes'): -41.73947368421052,\n",
       " ('1000-1100', 'piece_specific_endgames'): -43.34473684210526,\n",
       " ('1000-1100', 'special_moves'): -30.21052631578947,\n",
       " ('1000-1100', 'strategic_concepts'): -29.002631578947366,\n",
       " ('1000-1100', 'tactical_themes'): -26.623684210526314,\n",
       " ('1100-1200', 'advanced_tactical_themes'): -22.307894736842105,\n",
       " ('1100-1200', 'checkmate_patterns'): -17.571052631578944,\n",
       " ('1100-1200', 'checkmating_tactics'): -18.728947368421053,\n",
       " ('1100-1200', 'defensive_tactics'): -17.559473684210523,\n",
       " ('1100-1200', 'king_safety_and_attack'): -18.105263157894736,\n",
       " ('1100-1200', 'pawn_related_themes'): -15.684210526315788,\n",
       " ('1100-1200', 'piece_specific_endgames'): -14.028421052631577,\n",
       " ('1100-1200', 'special_moves'): -14.526315789473683,\n",
       " ('1100-1200', 'strategic_concepts'): -8.596315789473683,\n",
       " ('1100-1200', 'tactical_themes'): -9.95,\n",
       " ('1200-1300', 'advanced_tactical_themes'): -13.423684210526314,\n",
       " ('1200-1300', 'checkmate_patterns'): -4.7368421052631575,\n",
       " ('1200-1300', 'checkmating_tactics'): -4.7368421052631575,\n",
       " ('1200-1300', 'defensive_tactics'): -5.368421052631579,\n",
       " ('1200-1300', 'king_safety_and_attack'): -5.368421052631579,\n",
       " ('1200-1300', 'pawn_related_themes'): -7.7368421052631575,\n",
       " ('1200-1300', 'piece_specific_endgames'): -4.7368421052631575,\n",
       " ('1200-1300', 'special_moves'): -4.7368421052631575,\n",
       " ('1200-1300', 'strategic_concepts'): -4.7368421052631575,\n",
       " ('1200-1300', 'tactical_themes'): -4.7368421052631575,\n",
       " ('1300-1400', 'advanced_tactical_themes'): -2.3157894736842106,\n",
       " ('1300-1400', 'checkmate_patterns'): -3.0,\n",
       " ('1300-1400', 'checkmating_tactics'): -7.318421052631579,\n",
       " ('1300-1400', 'defensive_tactics'): -7.035263157894737,\n",
       " ('1300-1400', 'king_safety_and_attack'): -5.315789473684211,\n",
       " ('1300-1400', 'pawn_related_themes'): -6.0,\n",
       " ('1300-1400', 'piece_specific_endgames'): -2.3157894736842106,\n",
       " ('1300-1400', 'special_moves'): -9.947368421052632,\n",
       " ('1300-1400', 'strategic_concepts'): -13.631578947368421,\n",
       " ('1300-1400', 'tactical_themes'): -5.315789473684211,\n",
       " ('1400-1500', 'advanced_tactical_themes'): -3.0,\n",
       " ('1400-1500', 'checkmate_patterns'): -8.263157894736842,\n",
       " ('1400-1500', 'checkmating_tactics'): -3.0,\n",
       " ('1400-1500', 'defensive_tactics'): -6.789473684210526,\n",
       " ('1400-1500', 'king_safety_and_attack'): -3.0,\n",
       " ('1400-1500', 'pawn_related_themes'): -7.526315789473684,\n",
       " ('1400-1500', 'piece_specific_endgames'): -5.2631578947368425,\n",
       " ('1400-1500', 'special_moves'): -3.0,\n",
       " ('1400-1500', 'strategic_concepts'): -5.2631578947368425,\n",
       " ('1400-1500', 'tactical_themes'): -3.0,\n",
       " ('1500-1600', 'advanced_tactical_themes'): -5.2105263157894735,\n",
       " ('1500-1600', 'checkmate_patterns'): -5.2105263157894735,\n",
       " ('1500-1600', 'checkmating_tactics'): -3.0,\n",
       " ('1500-1600', 'defensive_tactics'): -4.421052631578947,\n",
       " ('1500-1600', 'king_safety_and_attack'): -6.0,\n",
       " ('1500-1600', 'pawn_related_themes'): -3.0,\n",
       " ('1500-1600', 'piece_specific_endgames'): -5.2105263157894735,\n",
       " ('1500-1600', 'special_moves'): -3.0,\n",
       " ('1500-1600', 'strategic_concepts'): -7.421052631578947,\n",
       " ('1500-1600', 'tactical_themes'): -7.421052631578947,\n",
       " ('1600-1700', 'advanced_tactical_themes'): -7.315789473684211,\n",
       " ('1600-1700', 'checkmate_patterns'): 0,\n",
       " ('1600-1700', 'checkmating_tactics'): -7.315789473684211,\n",
       " ('1600-1700', 'defensive_tactics'): 0,\n",
       " ('1600-1700', 'king_safety_and_attack'): -3.0,\n",
       " ('1600-1700', 'pawn_related_themes'): -8.157894736842106,\n",
       " ('1600-1700', 'piece_specific_endgames'): -2.1578947368421053,\n",
       " ('1600-1700', 'special_moves'): 0,\n",
       " ('1600-1700', 'strategic_concepts'): -3.0,\n",
       " ('1600-1700', 'tactical_themes'): 0,\n",
       " ('1700-1800', 'advanced_tactical_themes'): 0,\n",
       " ('1700-1800', 'checkmate_patterns'): -4.2105263157894735,\n",
       " ('1700-1800', 'checkmating_tactics'): -2.1052631578947367,\n",
       " ('1700-1800', 'defensive_tactics'): 0,\n",
       " ('1700-1800', 'king_safety_and_attack'): 0,\n",
       " ('1700-1800', 'pawn_related_themes'): -5.105263157894736,\n",
       " ('1700-1800', 'piece_specific_endgames'): 0,\n",
       " ('1700-1800', 'special_moves'): 0,\n",
       " ('1700-1800', 'strategic_concepts'): 0,\n",
       " ('1700-1800', 'tactical_themes'): -9.0,\n",
       " ('1800-1900', 'advanced_tactical_themes'): -5.052631578947368,\n",
       " ('1800-1900', 'checkmate_patterns'): -2.0526315789473686,\n",
       " ('1800-1900', 'checkmating_tactics'): -4.105263157894737,\n",
       " ('1800-1900', 'defensive_tactics'): 0,\n",
       " ('1800-1900', 'king_safety_and_attack'): 0,\n",
       " ('1800-1900', 'pawn_related_themes'): -6.0,\n",
       " ('1800-1900', 'piece_specific_endgames'): 0,\n",
       " ('1800-1900', 'special_moves'): -2.0526315789473686,\n",
       " ('1800-1900', 'strategic_concepts'): 0,\n",
       " ('1800-1900', 'tactical_themes'): -6.157894736842106,\n",
       " ('900-1000', 'advanced_tactical_themes'): 0,\n",
       " ('900-1000', 'checkmate_patterns'): -2.526315789473684,\n",
       " ('900-1000', 'checkmating_tactics'): 0,\n",
       " ('900-1000', 'defensive_tactics'): 0,\n",
       " ('900-1000', 'king_safety_and_attack'): 0,\n",
       " ('900-1000', 'pawn_related_themes'): 0,\n",
       " ('900-1000', 'piece_specific_endgames'): 0,\n",
       " ('900-1000', 'special_moves'): -5.526315789473684,\n",
       " ('900-1000', 'strategic_concepts'): -7.739473684210526,\n",
       " ('900-1000', 'tactical_themes'): 0,\n",
       " ('gt_1900', 'advanced_tactical_themes'): -2.0,\n",
       " ('gt_1900', 'checkmate_patterns'): -3.0,\n",
       " ('gt_1900', 'checkmating_tactics'): 0,\n",
       " ('gt_1900', 'defensive_tactics'): 0,\n",
       " ('gt_1900', 'king_safety_and_attack'): -8.465789473684211,\n",
       " ('gt_1900', 'pawn_related_themes'): 0,\n",
       " ('gt_1900', 'piece_specific_endgames'): -2.0,\n",
       " ('gt_1900', 'special_moves'): -2.0,\n",
       " ('gt_1900', 'strategic_concepts'): 0,\n",
       " ('gt_1900', 'tactical_themes'): -2.0,\n",
       " ('lt_900', 'advanced_tactical_themes'): 0,\n",
       " ('lt_900', 'checkmate_patterns'): -2.736842105263158,\n",
       " ('lt_900', 'checkmating_tactics'): 0,\n",
       " ('lt_900', 'defensive_tactics'): 0,\n",
       " ('lt_900', 'king_safety_and_attack'): -2.736842105263158,\n",
       " ('lt_900', 'pawn_related_themes'): -2.736842105263158,\n",
       " ('lt_900', 'piece_specific_endgames'): -5.160526315789474,\n",
       " ('lt_900', 'special_moves'): 0,\n",
       " ('lt_900', 'strategic_concepts'): -5.7368421052631575,\n",
       " ('lt_900', 'tactical_themes'): -2.423684210526316}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
